{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff38c5b0",
   "metadata": {},
   "source": [
    "\n",
    "# End-to-end: `uv` environment (Python 3.12) + CUDA PyTorch + PyG + Link Prediction (GCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47734c",
   "metadata": {},
   "source": [
    "## 0) Install `uv` (cross-platform hints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For Linux / macOS:\n",
    "# If curl is available:\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "# If wget is available:\n",
    "# !wget -qO- https://astral.sh/uv/install.sh | sh\n",
    "#\n",
    "# For Windows (PowerShell):\n",
    "# Set-ExecutionPolicy Bypass -Scope Process -Force; `\n",
    "#   [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; `\n",
    "#   irm https://astral.sh/uv/install.ps1 | iex\n",
    "#\n",
    "# After installing, you may need to restart your shell for PATH changes to take effect.\n",
    "# Test it by checking the version.\n",
    "!uv --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566181a7",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Create a Python 3.12 project named `test`\n",
    "This creates a virtual environment and a `pyproject.toml` you can pin dependencies into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679aff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pathlib, textwrap\n",
    "\n",
    "project_dir = pathlib.Path(\"test\").resolve()\n",
    "if project_dir.exists():\n",
    "    print(f\"Project already exists at: {project_dir}\")\n",
    "else:\n",
    "    project_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (project_dir / \"src\" / \"test\").mkdir(parents=True, exist_ok=True)\n",
    "    (project_dir / \"src\" / \"test\" / \"__init__.py\").write_text(\"\")\n",
    "    (project_dir / \"README.md\").write_text(\"# test\\n\\nProject created by the workshop tutorial notebook.\")\n",
    "    (project_dir / \".gitignore\").write_text(\".venv\\n__pycache__\\n*.pyc\\n\")\n",
    "    (project_dir / \"pyproject.toml\").write_text(textwrap.dedent(\"\"\"\n",
    "        [project]\n",
    "        name = \"test\"\n",
    "        version = \"0.1.0\"\n",
    "        description = \"GCN link prediction demo (PyTorch + PyG)\"\n",
    "        requires-python = \">=3.12\"\n",
    "\n",
    "        dependencies = [\n",
    "            # We will add heavy deps via explicit uv commands below to ensure correct wheels.\n",
    "        ]\n",
    "\n",
    "        [tool.uv]\n",
    "    \"\"\"))\n",
    "    print(f\"Created project at: {project_dir}\")\n",
    "\n",
    "print(\"If running locally, now run:\")\n",
    "print(\" uv python install 3.12\")\n",
    "print(\" cd test && uv venv --python 3.12 .venv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502c14d",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Install CUDA-enabled PyTorch and PyTorch Geometric with `uv`\n",
    "\n",
    "The default package here is **PyTorch `2.4.1` with `cu124` wheels** with an installation of **Pytorch-Geometric**  built for that exact torch/CUDA combination.\n",
    "\n",
    "You can use `cu124` PyTorch wheels as long as your **driver supports 12.x** (which the Liseda-cluster's drivers should!). For source builds or specifically conda-based CUDA 12.7 envs, adapt the commands accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5104b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, pathlib\n",
    "\n",
    "project_dir = pathlib.Path(\"test\").resolve()\n",
    "assert project_dir.exists(), \"Project folder not found. Run the previous cell first.\"\n",
    "\n",
    "TORCH_VERSION = os.environ.get(\"TORCH_VERSION\", \"2.4.1\")\n",
    "CUDA_TAG     = os.environ.get(\"TORCH_CUDA_TAG\", \"cu124\")  # e.g., cu121, cu124\n",
    "PYG_TAG      = os.environ.get(\"PYG_TORCH_TAG\", f\"{TORCH_VERSION}+{CUDA_TAG}\")  # e.g., 2.4.1+cu124\n",
    "\n",
    "print(\"Planned installs:\")\n",
    "print(f\"  torch=={TORCH_VERSION} ({CUDA_TAG})\")\n",
    "print(f\"  PyG wheels tag: torch-{PYG_TAG}\")\n",
    "\n",
    "torch_index = f\"https://download.pytorch.org/whl/{CUDA_TAG}\"\n",
    "torch_pkgs  = f\"torch=={TORCH_VERSION} torchvision torchaudio\"\n",
    "cmd1 = f'cd \"{project_dir}\" && uv pip install --index-url {torch_index} {torch_pkgs}'\n",
    "cmd2 = f'cd \"{project_dir}\" && uv pip install scikit-learn'\n",
    "pyg_find_links = f\"https://data.pyg.org/whl/torch-{PYG_TAG}.html\"\n",
    "cmd3 = f'cd \"{project_dir}\" && uv pip install pyg -f {pyg_find_links}'\n",
    "\n",
    "print(\"\\nRun locally in a terminal:\")\n",
    "print(cmd1)\n",
    "print(cmd2)\n",
    "print(cmd3)\n",
    "\n",
    "print(\"\\nVerify CUDA/GPU after installation:\")\n",
    "print(f'  cd \"{project_dir}\" && uv run python -c \"import torch; print(torch.__version__, torch.version.cuda, torch.cuda.is_available())\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea1626",
   "metadata": {},
   "source": [
    "### (Optional) Quick GPU check (after installing PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320249c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example (run in your system shell):\n",
    "#   cd test\n",
    "#   uv run python -c \"import torch; print(torch.__version__, torch.version.cuda, torch.cuda.is_available())\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72071e7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09467ade",
   "metadata": {},
   "source": [
    "\n",
    "## 4) GNNs Use-Case: Link Prediction with PyG's Planetoid Dataset\n",
    "\n",
    "make sure to run this **after** you have installed all dependencies into the `test/.venv`.  \n",
    "If you're running the notebook kernel from elsewhere, it’s okay — these cells will still demonstrate the full pipeline (assuming the required packages are importable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46085a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "try:\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "    import torch_geometric.transforms as T\n",
    "    from torch_geometric.nn import GCNConv\n",
    "except Exception as e:\n",
    "    print(\"PyTorch Geometric not available in the current kernel. \"\n",
    "          \"Run the uv installation commands and then restart the kernel using the 'test/.venv' interpreter.\")\n",
    "    raise\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb28d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Planetoid(root=\"data/Planetoid\", name=\"Cora\")\n",
    "data = dataset[0]\n",
    "\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.05, num_test=0.10, \n",
    "    is_undirected=True, \n",
    "    add_negative_train_samples=True\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa20dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def link_logits(z, edge_label_index):\n",
    "    src = z[edge_label_index[0]]\n",
    "    dst = z[edge_label_index[1]]\n",
    "    return (src * dst).sum(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GCN parameters\n",
    "\n",
    "in_dim = dataset.num_features\n",
    "hidden_dim = 128\n",
    "out_dim = 64\n",
    "model = GCN(in_dim, hidden_dim, out_dim).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "\n",
    "# Loss function (Binary Cross Entropy -- values between 0 and 1 -- is suitable for link prediction)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_split(split_data, train=False):\n",
    "    x = split_data.x.to(device)\n",
    "    edge_index = split_data.edge_index.to(device)\n",
    "    edge_label_index = split_data.edge_label_index.to(device)\n",
    "    edge_label = split_data.edge_label.to(device).float()\n",
    "\n",
    "    if train:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x, edge_index)\n",
    "        logits = link_logits(z, edge_label_index)\n",
    "        loss = criterion(logits, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss.item())\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            z = model(x, edge_index)\n",
    "            logits = link_logits(z, edge_label_index)\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            preds = (probs >= 0.5).astype(\"int32\")\n",
    "            labels = edge_label.detach().cpu().numpy()\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            f1 = f1_score(labels, preds)\n",
    "                roc = roc_auc_score(labels, probs)\n",
    "            return acc, f1, roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 100\n",
    "best_valid = -1.0\n",
    "best = {\"valid\": (0,0,0), \"test\": (0,0,0)}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss = run_split(train_data, train=True)\n",
    "    val_acc, val_f1, val_roc = run_split(val_data, train=False)\n",
    "    test_acc, test_f1, test_roc = run_split(test_data, train=False)\n",
    "\n",
    "    if val_f1 > best_valid:\n",
    "        best_valid = val_f1\n",
    "        best[\"valid\"] = (val_acc, val_f1, val_roc)\n",
    "        best[\"test\"] = (test_acc, test_f1, test_roc)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:03d} | loss={loss:.4f} | val: acc={val_acc:.4f} f1={val_f1:.4f} roc={val_roc:.4f}\"\n",
    "              f\" | test: acc={test_acc:.4f} f1={test_f1:.4f} roc={test_roc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nBest (by val F1)\")\n",
    "print(\"Val:  acc={:.4f}, f1={:.4f}, roc-auc={:.4f}\".format(*best[\"valid\"]))\n",
    "print(\"Test: acc={:.4f}, f1={:.4f}, roc-auc={:.4f}\".format(*best[\"test\"]))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
